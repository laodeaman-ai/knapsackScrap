import os
import requests
import csv
from bs4 import BeautifulSoup
from concurrent.futures import ThreadPoolExecutor

def fetch_table_from_url(base_url, keyword, max_retries=5, timeout=10):
    url = f"{base_url}{keyword.replace(' ', '%20')}"
    print(f"Mengambil data dari: {keyword}")
    response = requests.get(url)
    soup = BeautifulSoup(response.text, 'html.parser')
    table = soup.find('table', class_='sortable d1')
    if table:
        return table
    return None

def parse_table(table):
    rows = table.find_all('tr')
    headers = [header.text.strip() for header in table.find_all('th')]
    data = []
    for row in rows[1:]:
        cells = row.find_all('td')
        if len(cells) > 0:
            row_data = {headers[i]: cells[i].text.strip() for i in range(len(headers))}
            data.append(row_data)
    return data

def save_to_csv(data, filename):
    if not data:
        print("Data kosong, tidak ada yang disimpan.")
        return

    with open(filename, 'w', newline='', encoding='utf-8') as file:
        writer = csv.DictWriter(file, fieldnames=data[0].keys())
        writer.writeheader()
        writer.writerows(data)
    print(f"Data telah disimpan ke {filename}")

def fetch_smiles_data(row):
    smiles_id = row.get('C_ID')
    if smiles_id:
        print(f"Mengambil SMILES untuk ID: {smiles_id}")
        smiles = get_smiles_from_id(smiles_id)
        if smiles:
            row['smiles'] = smiles
    return row

def knapsackfamily(keywords):
    base_url = "http://www.knapsackfamily.com/knapsack_core/result.php?sname=organism&word="
    knapsack_csv = "./data_knapsack.csv"
    all_data = []

    for keyword in keywords:
        table = fetch_table_from_url(base_url, keyword)
        if table:
            table_data = parse_table(table)
            all_data.extend(table_data)
        else:
            print(f"Tidak ada data tabel untuk {keyword}.")

    if not all_data:
        print("Tidak ada data yang ditemukan.")
        return

    fieldnames = list(all_data[0].keys())
    if 'smiles' not in fieldnames:
        fieldnames.append('smiles')

    if os.path.exists(knapsack_csv):
        os.remove(knapsack_csv)
        print(f"File '{knapsack_csv}' telah dihapus untuk memulai proses baru.")

    new_rows = []
    max_workers = os.cpu_count() // 2
    with ThreadPoolExecutor(max_workers=max_workers) as executor:
        results = executor.map(fetch_smiles_data, all_data)

        for updated_row in results:
            if updated_row.get('smiles'):
                new_rows.append(updated_row)

    if new_rows:
        with open(knapsack_csv, 'w', newline='', encoding='utf-8') as csvfile:
            writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
            writer.writeheader()
            writer.writerows(new_rows)
            print(f"Berhasil menambahkan {len(new_rows)} baris baru ke '{knapsack_csv}'.")
    else:
        print("Tidak ada data baru yang ditambahkan.")

def get_smiles_from_id(row_id):
    url = f"http://www.knapsackfamily.com/knapsack_core/information.php?word={row_id}"
    response = requests.get(url)
    response.raise_for_status()

    soup = BeautifulSoup(response.text, 'html.parser')
    table = soup.find('table')
    if table:
        rows = table.find_all('tr')
        if len(rows) > 9:
            cols = rows[9].find_all('td')
            if len(cols) > 0:
                return cols[0].text.strip()
    return None

if __name__ == "__main__":
    # Contoh penggunaan
    keywords = ['Escherichia coli', 'Homo sapiens']  # Ganti dengan keyword yang sesuai
    knapsackfamily(keywords)
